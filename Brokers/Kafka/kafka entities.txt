https://www.youtube.com/watch?v=-AZOi3kP9Js

 ● Zookeeper - это сторонний сервис https://ru.wikipedia.org/wiki/Apache_ZooKeeper
 - хранит координацию, конфигурацию  и состояние кластера
 - внутри него есть небольшая БД
 - синхронизирует разные инстансы kafka
 - хранит айпишники реплицированных серверов

 ● Broker (он же Kafka Server или Kafka Node)
Прием, хранение и выдача сообщений. На Kafka-кластере можно создать много брокеров.
Брокер и обеспечивает надежность в Kafka, за счет того, что он там не один.
Брокеры синхронизируются между собой, создавая кластер

 ● Kafka controller
служебный брокер, обеспечивающий консистентность данных

 ● Message
 - Key - ключ (опциональный), используется для распределений сообщений по кластеру
 - Value - содержимое сообщения, массив байт
 - Timestamp
 - Headers - key-value аттрибуты

 ● Topic/Partition
 - Topic - это поток данных. На одном брокере может быть много топиков.
Внутри топика есть очередь. Сообщения в очередь складываются в том
порядке, в котором producer отправляет их. А считываем тоже в том порядке.
То есть FIFO. Тут отличие от RabbitMQ, где нет порядка, но есть приоритет.
Данные после чтения не удаляются из топика. То есть несколько разных
консумеров могут потреблять одни и те же данные.
 - Для high load было придумано очередь внутри топика разделить на партиции.
Кол-во партиций конфигурируемо.
Когда партиций больше одной, данные уже читаются не в том порядке, в котором
отправлял продюсер, а в том, вкотором они лежат партициях. FIFO per partition.
Кол-во партиций должно быть равно кол-ву конкурентно работающих консумеров.
Партиции хранятся в виде файлов на диске.


 ● Log-файлы
Все данные топика хранятся в log-файлах. В папке ./logs хранятся данные под
каждую партицию, например, подпапки .A-0, .A-1, .A-2 и тд. И уже внутри каждой
такой папки хранятся log-файлы каждой партиции:
 - .log - сами данные партиции
 - .index - маппинг оффсета
 - .timestamp - маппинг таймстемпа на оффсет

 ● Producer
 Функция send:
    - acks - гарантия доставки
        - 0 - не интересует гарантия доставки
        - 1 - продюсеру нужно подтверждение от Leader-реплики
        - all (или -1) - продюсер ждет подтверждения от всех реплик

 ● Consumer
 в Kafka есть отдельный топик __consumer_offsets, где хранятся offset'ы
 для каждой партиции.

 ● Consumer group - сущность, позволяющая объединять несколько реплик одного сервиса.
 Для того чтобы избежать дублирующейся работы нескольких реплик.

-----------------------------------------------------------------------------
Удаление данных. Возможно только автоматическое по TTL (time-to-live)
Данные удаляются партициями (не отдельными сообщениями)

-----------------------------------------------------------------------------
Репликация. Для каждой партиции у нас автоматически минимум 2 реплики.
Kafka controller (служебный контроллер) назначает Leader-реплику. Операции
чтения/записи производятся только с Leader-репликой. Follower-реплики
сами приходят к Leader-реплике, опрашивают ее и берут с нее данные.

