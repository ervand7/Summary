### Core requirements (what you restate back)
Functional

* Enforce rate limits for requests by a key (API key / user / IP / org / endpoint).
* Support multiple rules per request (e.g., org-wide + per-user + per-IP).
* Return decision: ALLOW or REJECT (+ metadata like remaining tokens, reset time).

Non-functional

* Very low latency check (usually single-digit ms).
* Highly available and horizontally scalable.
* Correct enough across many replicas (define strict vs approximate).
* Safe under failure (choose “fail-open” or “fail-closed” based on product).

---

### APIs (interview-friendly)

Option A (Gateway calls a limiter service)

* `POST /v1/ratelimit/check`

  * body:

    ```json
    {
      "key": "org:123:user:456",
      "rules": [
        {"name":"per_user", "limit":100, "window_ms":60000, "burst":20},
        {"name":"per_org",  "limit":5000,"window_ms":60000, "burst":200}
      ],
      "cost": 1,
      "now_ms": 1730000000000
    }
    ```
  * returns:

    ```json
    {
      "allowed": true,
      "reasons": [],
      "counters": [
        {"name":"per_user","remaining":42,"retry_after_ms":0},
        {"name":"per_org","remaining":3210,"retry_after_ms":0}
      ]
    }
    ```

Option B (best in practice): limiter is embedded in gateway/sidecar

* Gateway/sidecar does a Redis/Lua call directly (no extra hop).
* Still keep a “control plane” service for configs.

In interviews, I’d propose B as the “hot path” and still describe A as a simpler mental model.

---

### High-level architecture (recommended)

Two-plane design (this is “interview gold”)

#### 1) Data plane (hot path, per request)

Where decisions happen at very low latency.

* API Gateway / Envoy / NGINX / service middleware

  * extracts identity key
  * picks applicable rules
  * executes atomic update in a shared fast store (Redis cluster)
  * returns 200 or 429

#### 2) Control plane (configs + observability)

Not in the request path.

* Admin API to manage:

  * rules per endpoint / tenant
  * plan tiers
  * allowlists / blocklists
* Config distribution:

  * push via pub/sub, or pull cached with TTL
* Metrics pipeline:

  * allowed/blocked counts, top keys, latency

---

### Algorithm choice (what you pick and why)

You want to pick one confidently, then mention alternatives.

#### Default choice for interviews: Token Bucket (with Redis + Lua)

Why token bucket:

* Allows burst
* Smooth refill over time
* Easy to implement per key
* Widely used in gateways

Token bucket model per `(rule, key)`:

* state: `{tokens, last_refill_timestamp}`
* refill tokens based on elapsed time, capped at `burst` (capacity)
* if `tokens >= cost` → decrement and allow
* else reject and compute retry-after

Atomicity requirement: the refill + decrement must be atomic, so you do it in:

* Redis Lua script (single key)
  or
* Redis function / transaction pattern (Lua is standard)

---

### Storage model (what’s stored where)

#### Redis key design

For each rule, store per key:

* `rl:{rule}:{key}` → hash:

  * `tokens` (float/int)
  * `ts` (last_refill_ms)

Example:

* `rl:per_user:org:123:user:456`
* `rl:per_ip:1.2.3.4:/login`

TTL:

* Set TTL slightly larger than “time to refill to full” so inactive keys expire.
* This keeps memory bounded.

---

### Sharding / scaling Redis

At high RPS you need Redis cluster.

* Shard by the Redis key (built-in cluster hashing).
* Hot keys problem (single abusive key):

  * can still hot-spot on one shard — but that’s okay because it’s one key
  * mitigate with:

    * strict blocks at edge/WAF
    * per-IP early drop
    * optional local pre-check to reduce Redis hits

---

### Reducing latency and cost (important)

Calling Redis for every request can be expensive at very high RPS.

Common approach:

#### Local (in-process) limiter + global (Redis) limiter

* Local limiter (in gateway instance):

  * small in-memory token bucket
  * allows most requests without Redis roundtrip
* Periodically reconcile / reserve tokens from Redis in batches:

  * “token leasing”:

    * gateway asks Redis for a chunk (e.g., 100 tokens)
    * then spends locally until depleted

This is more complex but a strong senior-level answer.
If time is short, mention it as an optimization.

---

### Consistency model (be explicit)

* Strict global enforcement: every request checks Redis (accurate, more latency/cost).
* Approximate: local buckets with leasing (very fast, small error margin).

Interview line:

> “Default: strict Redis atomic check for correctness. If throughput becomes the bottleneck, introduce token leasing to reduce shared-store QPS.”

---

### Failure handling (this is where many candidates fail)

Decide policy with interviewer:

* Fail-open (allow if limiter store is down)

  * good for user experience
  * risky for protecting expensive backend
* Fail-closed (block if limiter store is down)

  * protects backend
  * can cause outage-like behavior

A common compromise:

* For login / expensive endpoints → fail-closed
* For general traffic → fail-open with a conservative local limiter

Also:

* Circuit breaker around Redis
* Timeouts (e.g., 2–5ms) so limiter doesn’t become latency tail

---

### Observability

Metrics (tag by rule + endpoint + tenant):

* `rate_limiter_allowed_total`
* `rate_limiter_blocked_total`
* `rate_limiter_latency_ms` (p50/p99)
* `redis_errors_total`
* Top-N offending keys (sampled)

Logs:

* sample only (don’t log every request)

---

### Capacity planning (simple, but shows you think)

If peak is 200k RPS and every request hits Redis:

* Redis must handle ~200k ops/sec * number_of_rules_per_request
* If each request checks 2 rules → 400k ops/sec (too high for one node)
  So you either:
* shard Redis cluster, and/or
* reduce calls with token leasing, and/or
* keep rule count per request small, and/or
* apply limiter at edge earlier (CDN/WAF)
