üëâ Cache stampede ‚Äî —ç—Ç–æ –∫–æ–≥–¥–∞ –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–æ–º–∞—Ö–∏–≤–∞—é—Ç—Å—è –ø–æ 
–∫—ç—à—É –∏ –≤—Å–µ –∏–¥—É—Ç –≤ –ë–î.

–ö–æ—Ä–æ—Ç–∫–æ:
* –ö–ª—é—á –≤ –∫—ç—à–µ –∏—Å—Ç—ë–∫ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
* –¢—ã—Å—è—á–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–∏—Ö–æ–¥—è—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
* –í—Å–µ –¥–µ–ª–∞—é—Ç –∑–∞–ø—Ä–æ—Å –∫ –ë–î
* –ë–î –ø–µ—Ä–µ–≥—Ä—É–∂–∞–µ—Ç—Å—è

üëâ A cache stampede (thundering herd) happens when many concurrent requests
miss the cache at the same time and all hit the database or downstream service
simultaneously, causing overload.

Why cache stampedes happen:
* Cache entry expires (TTL) for a hot key
* Cache is cold after deploy or autoscaling
* Cache eviction under memory pressure
* Popular data accessed by many clients at once

What goes wrong during a stampede:
* Hundreds or thousands of requests hit DB at once
* DB latency spikes or connections are exhausted
* Requests pile up in memory
* Cascading failures across services
* System becomes unstable instead of faster

Typical real-world scenario:
* Hot key expires at time T
* 1,000 requests arrive at time T+Œµ
* All miss cache
* All query DB
* DB collapses

Common stampede prevention techniques:
1Ô∏è‚É£ Request coalescing - –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∫–ª—é—á–∞
* Only one request recomputes the value
* Other requests wait for the result

Pros:
* Simple and effective
* No DB overload

Cons:
* Waiting requests add latency


2Ô∏è‚É£ Explicit invalidation
3Ô∏è‚É£ TTL jitter (randomized expiration) - –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–Ω—ã—Ö –∫–ª—é—á–µ–π
4Ô∏è‚É£ Background refresh