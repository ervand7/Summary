Google Kubernetes Engine настраивает многоузловой кластер.
Minikube настраивает одноузловой кластер.
 ● minikube start
 ● k cluster-info
 ● k run kubia --image=ervand7/kubia --port=8080
 создадим pod

Нужно создать контроллер репликации. Он гарантирует, что всегда имеется ровно один
экземпляр нашего пода. И он используется для создания репликаций (нескольких копий)
пода. В нашем случае мы не указываем сколько реплик требуется, поэтому rc создаст
единственный:
 ● k create -f kubia.yaml
 создадим контроллер репликации

 ● k get pods
 ● k describe pod

Каждый pod имеет собственный ip-адрес и хостнейм. Поды эфемерны. И если rc заменит
под на новый, то у нового будет уже новый ip-адрес и хостнейм. И благодаря service
мы можем не переживать насчет этого.
Адреса подов являются внутренним и недоступными извне. Для того, чтобы под получил
внешний адрес, нужно создать Service с типом LoadBalancer. Будет создана внешняя подсистема
балансировки нагрузки и мы сможем подключиться к поду через общедоступный ip-адрес
этой подсистемы балансировки (НЕДОСТУПНО ДЛЯ minikube):
 ● k expose rc kubia --type=LoadBalancer --name=kubia-http
 создадим объект Service
 ● k get services

 ● minikube service kubia-http
 получаем внешний адрес пода через minikube (открываем туннель)
 ● curl http://127.0.0.1:53441
 достукиваемся до нашего приложения

Горизонтальное масштабирование:
 ● k get rc
 получаем наши rc
 ● k scale rc kubia --replicas=3
 увеличиваем кол-во реплик до 3
 ● k get rc
 ● k get pods
 ● set -B ; for i in {1..10}; do curl http://127.0.0.1:53441 ; done
 в цикле 10 раз запускаем обращение к нашей программе и видим, что попадаем
 на разные реплики. Видим, что service, имеющий несколько экземпляров пода
 балансирует нагрузку и распределяет запросы по всем 3 модулям.
 ● k get pods -o wide
 вывод расширенной информации ip-адресами и инфо про ноды
 ● k describe pod kubia-8cv7z
 подробно смотрим инфо про конкретный под

Dashboard:
 ● minikube dashboard
