## What does ‚Äúhigh RPS‚Äù actually mean?

RPS (Requests Per Second) is simply:
> How many requests a system processes per second

So:
* 100 RPS ‚Üí 100 requests/sec
* 10,000 RPS ‚Üí 10,000 requests/sec
* 100,000+ RPS ‚Üí typically considered ‚Äúhigh RPS‚Äù

But by itself, this number means almost nothing.

## Why ‚Äúhigh RPS‚Äù is misleading on its own
### 1Ô∏è‚É£ RPS says nothing about request cost

100 RPS can be:
* `GET /health` returning `"ok"`
* OR `POST /checkout` with:
  * DB transactions
  * external API calls
  * fraud checks
  * synchronous Kafka writes

Same RPS ‚Üí orders of magnitude different load
> Interviewer phrase:
> ‚ÄúRPS without understanding request complexity is meaningless.‚Äù


### 2Ô∏è‚É£ RPS hides latency
Two systems:
* System A: 10k RPS, p99 = 20ms
* System B: 10k RPS, p99 = 2 seconds

Same RPS ‚Äî completely different user experience and stability.
High RPS with high latency often means:
* thread / goroutine pile-ups
* DB saturation
* connection pool exhaustion


### 3Ô∏è‚É£ RPS ignores concurrency
RPS is a *rate*, not *parallelism*.

Example:
* 1000 RPS
* average latency = 1 second
That means:
~1000 concurrent in-flight requests

If latency increases to 2s:
~2000 concurrent requests

üëâ Even if RPS stays the same, resource usage doubles.

> Key formula interviewers love:
```
Concurrency ‚âà RPS √ó Latency
```


### 4Ô∏è‚É£ RPS doesn‚Äôt show tail behavior (p95 / p99)
Most failures appear in:
* p95
* p99
* p99.9

Example:
* average latency = 50ms
* p99 latency = 5s

System ‚Äúhandles‚Äù the RPS, but:
* connections pile up
* retries start
* timeouts trigger
* cascading failures begin

RPS looks fine ‚Üí system is actually dying.


### 5Ô∏è‚É£ RPS ignores error rate
10k RPS with:
* 0.01% errors ‚Üí healthy
* 5% errors ‚Üí production incident

RPS alone doesn‚Äôt tell you:
* how many requests fail
* whether failures spike under load


### 6Ô∏è‚É£ RPS is endpoint-dependent
High RPS for:
* `/metrics`
* `/health`
* `/status`

‚â†
High RPS for:
* `/checkout`
* `/transfer`
* `/create-order`

Senior engineers always ask:
> ‚ÄúHigh RPS of what exactly?‚Äù


## What metrics matter *together* with RPS
A senior answer always expands RPS into a set:
* RPS ‚Äì traffic volume
* Latency (p50 / p95 / p99) ‚Äì responsiveness
* Concurrency ‚Äì memory & goroutine pressure
* Error rate ‚Äì correctness
* Resource usage ‚Äì CPU, memory, GC, DB pools
* Dependency latency ‚Äì DB, cache, APIs


## Perfect interview answer (concise)
> ‚ÄúHigh RPS just means a lot of requests per second, but by itself it‚Äôs misleading.
> RPS doesn‚Äôt reflect request complexity, latency, concurrency, or error rate.
> Two systems can have the same RPS and completely different load profiles.
> In practice, I always evaluate RPS together with latency percentiles, concurrency,
and downstream dependency behavior.‚Äù
