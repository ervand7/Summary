ðŸ‘‰ Because scaling out increases coordination, contention, and pressure on shared 
resources.

What people expect:
* More instances â†’ more capacity â†’ higher throughput

What actually happens:
* All instances still depend on shared bottlenecks
* Contention grows faster than useful work

Common reasons throughput drops:
* Shared database saturation â€” more instances = more DB connections and lock contention
* Connection pool exhaustion â€” DB / Redis / external APIs become overloaded
* Increased latency â€” causes higher concurrency and resource usage
* Lock contention â€” on shared caches, queues, or coordination services
* Load balancer imbalance â€” traffic is not evenly distributed

Hidden amplification effects:
* More instances generate more retries under partial failures
* More network chatter (heartbeats, health checks, coordination)
* GC and memory pressure increases across the fleet

Key insight:
* Scaling works only if bottlenecks are also scalable
* Adding instances without removing shared limits makes things worse

One-line interview answer:
> Adding more instances can reduce throughput when shared dependencies like databases,
caches, or external services become bottlenecks, increasing contention, latency, and
retries instead of parallelism.
