 ● PC - The program counter (PC), which is sometimes called the instruction
 pointer (IP), is what allows the Thread to keep track of the next instruction
 to execute. In most processors, the PC points to the next instruction
 and not the current instruction.

 ● Thread States - Waiting, Runnable and Executing
    - Waiting: This means the Thread is stopped and waiting for something in
    order to continue. This could be for reasons like waiting for the hardware
    (disk, network), the operating system (system calls) or synchronization
    calls (atomic, mutexes). These types of latencies are a root cause for bad
    performance.

    - Runnable: This means the Thread wants time on a core so it can execute
    its assigned machine instructions. If you have a lot of Threads that want
    time, then Threads have to wait longer to get time. Also, the individual
    amount of time any given Thread gets is shortened, as more Threads compete
    for time. This type of scheduling latency can also be a cause of bad performance.

    - Executing: This means the Thread has been placed on a core and is
    executing its machine instructions. The work related to the application
    is getting done. This is what everyone wants

 ● Types Of Work - CPU-Bound and I/O-Bound
    - CPU-Bound: This is work that never creates a situation where the Thread
    may be placed in Waiting states. This is work that is constantly making
    calculations. A Thread calculating Pi to the Nth digit would be CPU-Bound.

    - I/O-Bound: This is work that causes Threads to enter into Waiting states.
    This is work that consists in requesting access to a resource over the
    network or making system calls into the operating system. A Thread that
    needs to access a database would be I/O-Bound. I would include
    synchronization events (mutexes, atomic), that cause the Thread to
    wait as part of this category.

 ● Context Switching - the physical act of swapping Threads on a core is called
 context switching. A context switch happens when the scheduler pulls an
 Executing thread off a core and replaces it with a Runnable Thread. The
 Thread that was selected from the run queue moves into the Executing state.
 The Thread that was pulled can move back into the Runnable state (if it
 still has the ability to run), or into the Waiting state (if was
 replaced because of an I/O-Bound type of request).

 Context switches are considered to be expensive because it takes time to swap
 Threads on and off a core. The amount of latency incurred during a context
 switch depends on different factors, but it’s not unreasonable for it to
 take between ~1000 and ~1500 nanoseconds.

 If you have a program that is focused on I/O-Bound work, then context switches
 are going to be an advantage. Once a Thread moves into a Waiting state, another
 Thread in a Runnable state is there to take its place. This allows the core to
 always be doing work. This is one of the most important aspects of scheduling.
 Don’t allow a core to go idle if there is work (Threads in a Runnable state)
 to be done.

 If your program is focused on CPU-Bound work, then context switches are going
 to be a performance nightmare. Since the Thread always has work to do, the
 context switch is stopping that work from progressing. This situation is in
 stark contrast with what happens with an I/O-Bound workload.
